{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "import matplotlib.gridspec as gridspec\n",
    "plt.rcParams[\"font.family\"] = \"Optima\"\n",
    "plt.rcParams[\"font.weight\"] = \"light\"\n",
    "\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "import arviz as az\n",
    "import numpyro\n",
    "from numpyro.infer import MCMC, NUTS, init_to_median\n",
    "\n",
    "import numpy as np\n",
    "from jax import random\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-immune",
   "metadata": {},
   "source": [
    "# Define Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\"Netherlands\", \"United Kingdom\", \"Czech Republic\", \"Ireland\", \"Belgium\", \"Hungary\"]\n",
    "Ds = pd.date_range('2021-01-01', '2021-05-23')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-breathing",
   "metadata": {},
   "source": [
    "# Load Case Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "oxcgrt_df = pd.read_csv('OxCGRT_latest.csv') # to run this notebook, please download \n",
    "oxcgrt_df[\"Date\"] = pd.to_datetime(oxcgrt_df[\"Date\"], format=\"%Y%m%d\")\n",
    "oxcgrt_df = oxcgrt_df.set_index(['CountryName', 'Date'])\n",
    "\n",
    "new_cases = np.zeros((len(countries), len(Ds)))\n",
    "for c_i, c in enumerate(countries):\n",
    "    if c != \"United Kingdom\":\n",
    "        new_cases[c_i, :] = np.array(oxcgrt_df.loc[c][\"ConfirmedCases\"].diff().loc[Ds])\n",
    "    else:\n",
    "        uk_df = oxcgrt_df.loc[\"United Kingdom\"].reset_index()\n",
    "        uk_df = uk_df.set_index(['RegionName', 'Date'])\n",
    "        new_cases[c_i, :] = np.array(uk_df.loc[\"England\"][\"ConfirmedCases\"].diff().loc[Ds])\n",
    "\n",
    "# observe 30 days of cases, only.\n",
    "new_cases = np.ma.array(new_cases)\n",
    "new_cases[:, :10] = np.ma.masked\n",
    "new_cases[new_cases<1] = np.ma.masked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-leone",
   "metadata": {},
   "source": [
    "# Load NPI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_df = pd.read_csv('npi_data.csv')\n",
    "npi_df[\"Date\"] = pd.to_datetime(npi_df[\"Date\"], format=\"%Y%m%d\")\n",
    "npi_df = npi_df.set_index(['CountryName', 'Date'])\n",
    "\n",
    "active_cms_sw = np.zeros((len(countries), 19, len(Ds)))\n",
    "active_cms_fw = np.zeros((len(countries), 8, len(Ds)))\n",
    "\n",
    "sw_npis = list(npi_df.columns[:19])\n",
    "fw_npis = list(npi_df.columns[19:])\n",
    "\n",
    "# only have NPI data til 135\n",
    "for c_i, c in enumerate(countries):\n",
    "    for npi_i, npi in enumerate(sw_npis):\n",
    "        active_cms_sw[c_i, npi_i, :135] = npi_df.loc[c][npi]\n",
    "        active_cms_sw[c_i, npi_i, 135:] = active_cms_sw[c_i, npi_i, 134]\n",
    "        \n",
    "for c_i, c in enumerate(countries):\n",
    "    for npi_i, npi in enumerate(fw_npis):\n",
    "        active_cms_fw[c_i, npi_i, :135] = npi_df.loc[c][npi]\n",
    "        active_cms_fw[c_i, npi_i, 135:] = active_cms_fw[c_i, npi_i, 134]\n",
    "        \n",
    "active_cms_all = np.zeros((len(countries), 27, len(Ds)))\n",
    "active_cms_all[:, :19, :] = active_cms_sw\n",
    "active_cms_all[:, -8:, :] = active_cms_fw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_cms_to_shock_cms(active_cms, cm_alphas):\n",
    "    nCs, nCMs, nDs = active_cms.shape\n",
    "    \n",
    "    shock_cms = np.zeros((nCs, 0, nDs))\n",
    "    \n",
    "    shock_cms_info = []\n",
    "    cm_index = 0\n",
    "    \n",
    "    mask = np.ones(nCMs)\n",
    "    mask[5:8] = 0 #secondwave schools\n",
    "    mask[-3:-1] = 0 #firstwave schools\n",
    "    \n",
    "    for c_i in range(nCs):\n",
    "        total_cms_active = np.sum(active_cms[c_i, :, :], axis=0)\n",
    "        total_cms_changed = np.zeros_like(total_cms_active)\n",
    "        total_cms_changed[1:] = np.diff(total_cms_active)\n",
    "        cm_changes = np.nonzero(total_cms_changed)[0]\n",
    "        \n",
    "        for change in cm_changes:\n",
    "            shock_cm = np.zeros((nCs, 1, nDs))\n",
    "            shock_cm[c_i, 0, change:] = 1\n",
    "            shock_cms = np.append(shock_cms, shock_cm, axis=1)\n",
    "            \n",
    "            cm_delta_sw = np.sum(active_cms[c_i, :19, change-1]*cm_alphas[:, :19], axis=-1) - np.sum(active_cms[c_i, :19, change]*cm_alphas[:, :19], axis=-1)\n",
    "            cm_delta_fw = np.sum(active_cms[c_i, -8:, change-1]*cm_alphas[:, -8:], axis=-1) - np.sum(active_cms[c_i, -8:, change]*cm_alphas[:, -8:], axis=-1)\n",
    "                \n",
    "            act_cm_delta_nm = np.sum(active_cms[c_i, :, change-1]) - np.sum(active_cms[c_i, :, change])\n",
    "            act_cm_delta = np.sum(active_cms[c_i, :, change-1]*mask) - np.sum(active_cms[c_i, :, change]*mask)\n",
    "            \n",
    "            total_change = max(np.abs(np.sum(active_cms[c_i, :19, change-1]) - np.sum(active_cms[c_i, :19, change])), \n",
    "                                                np.abs(np.sum(active_cms[c_i, -8:, change-1]) - np.sum(active_cms[c_i, -8:, change])))\n",
    "            if act_cm_delta < 0:\n",
    "                reopening = True\n",
    "            else:\n",
    "                reopening = False\n",
    "            \n",
    "            shock_cms_info.append((cm_index, cm_delta_sw, cm_delta_fw, reopening, change, c_i, total_change))\n",
    "            cm_index += 1\n",
    "        \n",
    "    return shock_cms, shock_cms_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_res = az.from_netcdf('final_results/final_results2.netcdf') # to run this file, you will need to do a main model run, and save the results as a .netcdf file\n",
    "cm_alpha_sw = full_res.posterior.alpha_i.data.reshape((5000, 19))\n",
    "cm_alpha_sw[:, 5] = np.sum(cm_alpha_sw[:, 5:8], axis=-1)/3\n",
    "cm_alpha_sw[:, 6] = np.sum(cm_alpha_sw[:, 5:8], axis=-1)/3\n",
    "cm_alpha_sw[:, 7] = np.sum(cm_alpha_sw[:, 5:8], axis=-1)/3\n",
    "\n",
    "cm_alpha_fw = -np.log(np.loadtxt('fw_alpha.txt'))\n",
    "cm_alpha_fw[:, -3] = 2*np.sum(cm_alpha_fw[:, -3:-1], axis=-1)/3\n",
    "cm_alpha_fw[:, -2] = 1*np.sum(cm_alpha_fw[:, -3:-1], axis=-1)/3\n",
    "cm_alpha_all = np.zeros((5000, 27))\n",
    "cm_alpha_all[:, :19] = cm_alpha_sw\n",
    "cm_alpha_all[:, -8:] = cm_alpha_fw[:5000, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-understanding",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") \n",
    "\n",
    "from epimodel import preprocess_data, run_model, EpidemiologicalParameters, default_model\n",
    "from epimodel.models.model_build_utils import *\n",
    "\n",
    "ep = EpidemiologicalParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shock_rw_model(ep, new_cases, shock_cms, r_walk_period=7, seeding_scale=4):\n",
    "    nRs, nDs = new_cases.shape\n",
    "    _, nShock, _ = shock_cms.shape\n",
    "    \n",
    "    n_days_seeding = 7\n",
    "    alpha_delta = numpyro.sample(\"alpha_delta\", dist.Normal(loc=0, scale=0.25*jnp.ones(nShock)))\n",
    "#     alpha_delta = numpyro.sample(\"alpha_delta\", dist.Uniform(low=-0.5, high=0.5*jnp.ones(nShock)))\n",
    "    \n",
    "    basic_R = numpyro.sample(\"basic_R\", dist.Normal(loc=1.2*np.ones(nRs), scale=0.5))\n",
    "    cm_reduction = jnp.sum(shock_cms * alpha_delta.reshape((1, nShock, 1)), axis=1)\n",
    "    nNP = int(nDs / r_walk_period) - 1\n",
    "    r_walk_noise_scale = numpyro.sample(\"r_walk_noise_scale\", dist.HalfNormal(0.15))\n",
    "\n",
    "    r_walk_noise = numpyro.sample(\n",
    "        \"r_walk_noise\",\n",
    "        dist.Normal(loc=jnp.zeros((1, nNP)), scale=1.0 / 10),\n",
    "    )\n",
    "\n",
    "    expanded_r_walk_noise = jnp.repeat(\n",
    "        r_walk_noise_scale * 10.0 * jnp.cumsum(r_walk_noise, axis=-1),\n",
    "        r_walk_period,\n",
    "        axis=-1,\n",
    "    )[: nRs, : (nDs - 2 * r_walk_period)]\n",
    "\n",
    "    full_log_Rt_noise = jnp.zeros((nRs, nDs))\n",
    "    full_log_Rt_noise = jax.ops.index_update(\n",
    "        full_log_Rt_noise, jax.ops.index[:, 2 * r_walk_period :], expanded_r_walk_noise\n",
    "    )\n",
    "\n",
    "    Rt = numpyro.deterministic(\n",
    "        \"Rt\",\n",
    "        jnp.exp(\n",
    "            jnp.log(basic_R.reshape((nRs, 1))) + full_log_Rt_noise - cm_reduction\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    seeding_padding = n_days_seeding\n",
    "    total_padding = ep.GIv.size - 1\n",
    "\n",
    "    init_infections, total_infections_placeholder = seed_infections(\n",
    "        seeding_scale, nRs, nDs, seeding_padding, total_padding\n",
    "    )\n",
    "    discrete_renewal_transition = get_discrete_renewal_transition(ep)\n",
    "\n",
    "    _, infections = jax.lax.scan(\n",
    "        discrete_renewal_transition,\n",
    "        init_infections,\n",
    "        Rt.T,\n",
    "    )\n",
    "\n",
    "    total_infections = jax.ops.index_update(\n",
    "        total_infections_placeholder,\n",
    "        jax.ops.index[:, :seeding_padding],\n",
    "        init_infections[:, -seeding_padding:],\n",
    "    )\n",
    "    total_infections = numpyro.deterministic(\n",
    "        \"total_infections\",\n",
    "        jax.ops.index_update(\n",
    "            total_infections, jax.ops.index[:, seeding_padding:], infections.T\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    future_cases_t = numpyro.deterministic(\"future_cases_t\", total_infections)\n",
    "\n",
    "    expected_cases = numpyro.deterministic(\n",
    "        \"expected_cases\",\n",
    "        jax.scipy.signal.convolve2d(future_cases_t, ep.DPC, mode=\"full\")[\n",
    "            :, seeding_padding : seeding_padding + nDs\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    psi_cases = numpyro.sample(\n",
    "        \"psi_cases\",\n",
    "        dist.HalfNormal(scale=5. * jnp.ones((len(countries), 1)))\n",
    "    )\n",
    "\n",
    "    with numpyro.handlers.mask(mask=jnp.logical_not(new_cases.mask)):\n",
    "        numpyro.sample(\n",
    "            \"observed_cases\",\n",
    "            dist.GammaPoisson(\n",
    "                concentration=psi_cases,\n",
    "                rate=psi_cases / expected_cases,\n",
    "            ),\n",
    "            obs=new_cases.data,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-fifth",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "shock_cms_comb, shock_cms_info_comb = active_cms_to_shock_cms(active_cms_all, cm_alpha_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "shock_cms_comb, shock_cms_info_comb = active_cms_to_shock_cms(active_cms_all, cm_alpha_all)\n",
    "\n",
    "nuts_kernel = NUTS(\n",
    "        shock_rw_model,\n",
    "        init_strategy=init_to_median,\n",
    "        max_tree_depth=15,\n",
    "    )\n",
    "\n",
    "mcmc = MCMC(\n",
    "    nuts_kernel,\n",
    "    num_samples=500,\n",
    "    num_warmup=250,\n",
    "    num_chains=1,\n",
    "    chain_method=\"sequential\"\n",
    ")\n",
    "rng_key = random.PRNGKey(0)\n",
    "\n",
    "mcmc.run(rng_key, ep, new_cases, shock_cms_comb)\n",
    "samples_shock = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-ranking",
   "metadata": {},
   "source": [
    "# Validate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_i in range(len(countries)):\n",
    "    plt.figure(figsize=(4.75, 2.75), dpi=200)\n",
    "    plt.subplot(121)\n",
    "    rt = samples_shock['Rt'][:, c_i, :]\n",
    "    plt.fill_between(Ds, np.percentile(rt, 2.5, axis=0), np.percentile(rt, 97.5, axis=0), alpha=0.2, color=\"tab:purple\", linewidth=0)\n",
    "    plt.plot(Ds, np.percentile(rt, 50, axis=0), color=\"tab:purple\")\n",
    "    plt.ylim([0.25, 2])\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))\n",
    "    plt.xticks(fontsize=8, rotation=-45, ha='left')\n",
    "    plt.ylabel('$R_t$')\n",
    "\n",
    "    for _, _, _, _, d, c in shock_cms_info_comb:\n",
    "        if c == c_i:\n",
    "            plt.axvline(Ds[d], color='k', linewidth=0.5, alpha=0.5)\n",
    "            \n",
    "    plt.xlim([Ds[7], Ds[-1]])\n",
    "    plt.xticks(Ds[7::20], fontsize=8, rotation=-45, ha='left')\n",
    "\n",
    "        \n",
    "    plt.subplot(122)\n",
    "    ac = new_cases[c_i, :]\n",
    "    ec_fw = samples_shock['expected_cases'][:, c_i, :]\n",
    "    plt.fill_between(Ds, np.percentile(ec_fw, 2.5, axis=0), np.percentile(ec_fw, 97.5, axis=0), alpha=0.2, color=\"tab:orange\")\n",
    "    plt.plot(Ds, np.percentile(ec_fw, 50, axis=0), color=\"tab:orange\")\n",
    "\n",
    "\n",
    "    plt.scatter(Ds[~ac.mask], ac[~ac.mask], s=4, color='tab:blue', marker='.')\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b\"))\n",
    "    plt.xlim([Ds[7], Ds[-1]])\n",
    "    plt.xticks(fontsize=8, rotation=-45, ha='left')\n",
    "    plt.xticks(Ds[7::20], fontsize=8, rotation=-45, ha='left')\n",
    "    \n",
    "    plt.ylabel('Reported Cases')\n",
    "    plt.ylim([0, 1.15*np.max(new_cases[c_i, 7:-10].data)])\n",
    "\n",
    "    plt.suptitle(countries[c_i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-sense",
   "metadata": {},
   "source": [
    "# Summarise Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_reopenings = False\n",
    "\n",
    "last_day = 120 #may 1st\n",
    "# second wave\n",
    "sw_shock_values = 100*(1-np.exp(-np.median(samples_shock['alpha_delta'], axis=0)))\n",
    "sw_shock_values_pred = 100*(1-np.exp(np.array([x for _, x, _, _, _, _, _ in shock_cms_info_comb]))).T\n",
    "sw_reopening_mask = np.array([x for _, _,_, x, _, _, _ in shock_cms_info_comb])\n",
    "\n",
    "npis_changd = np.array([x for _, _,_, _, _, _, x in shock_cms_info_comb])\n",
    "\n",
    "if ignore_reopenings:\n",
    "    sw_shock_values[sw_reopening_mask] = np.nan\n",
    "\n",
    "for s_i in range(len(shock_cms_info_comb)):\n",
    "    if shock_cms_info_comb[s_i][4] >= last_day:\n",
    "        sw_shock_values[s_i] = np.nan\n",
    "        sw_shock_values_pred[:, s_i] = np.nan\n",
    "        npis_changd[s_i] = np.nan\n",
    "    \n",
    "sw_made = np.nanmean(np.abs(sw_shock_values - np.median(sw_shock_values_pred, axis=0)))\n",
    "sw_mse = np.nanmean(np.power(sw_shock_values - np.median(sw_shock_values_pred, axis=0), 2))\n",
    "sw_mse_ps = np.power(sw_shock_values - np.median(sw_shock_values_pred, axis=0), 2)\n",
    "\n",
    "# first wave\n",
    "fw_shock_values = 100*(1-np.exp(-np.median(samples_shock['alpha_delta'], axis=0)))\n",
    "fw_shock_values_pred = 100*(1-np.exp(np.array([x for _, _, x, _, _, _, _ in shock_cms_info_comb]))).T\n",
    "fw_reopening_mask = np.array([x for _,_, _, x, _, _, _ in shock_cms_info_comb])\n",
    "\n",
    "if ignore_reopenings:\n",
    "    fw_shock_values[fw_reopening_mask] = np.nan\n",
    "    \n",
    "for s_i in range(len(shock_cms_info_comb)):\n",
    "    if shock_cms_info_comb[s_i][4] >= last_day:\n",
    "        fw_shock_values[s_i] = np.nan\n",
    "        fw_shock_values_pred[:, s_i] = np.nan\n",
    "\n",
    "fw_made = np.nanmean(np.abs(fw_shock_values - np.median(fw_shock_values_pred, axis=0)))\n",
    "fw_mse = np.nanmean(np.power(fw_shock_values - np.median(fw_shock_values_pred, axis=0), 2))\n",
    "fw_mse_ps = np.power(fw_shock_values - np.median(fw_shock_values_pred, axis=0), 2)\n",
    "\n",
    "obs_mean = np.nanmean(np.abs(sw_shock_values))\n",
    "sw_mean = np.nanmean(np.abs(sw_shock_values_pred))\n",
    "fw_mean = np.nanmean(np.abs(fw_shock_values_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_under_overestimate(fw, sw, observed):\n",
    "    nS = observed.size\n",
    "    errors_fw = np.zeros(nS)\n",
    "    errors_sw = np.zeros(nS)\n",
    "    \n",
    "    pred_meds_fw = np.median(fw, axis=0)\n",
    "    pred_meds_sw = np.median(sw, axis=0)\n",
    "    \n",
    "    for i in range(nS):\n",
    "        closing = np.logical_or(pred_meds_fw[i] >0, pred_meds_sw[i] > 0)\n",
    "        \n",
    "        if closing:\n",
    "            fw_err = pred_meds_fw[i] - observed[i]\n",
    "            sw_err = pred_meds_sw[i] - observed[i]\n",
    "        else:\n",
    "            fw_err = -pred_meds_fw[i] + observed[i]\n",
    "            sw_err = -pred_meds_sw[i] + observed[i]\n",
    "        \n",
    "        errors_fw[i] = fw_err\n",
    "        errors_sw[i] = sw_err\n",
    "    \n",
    "    return np.nanmean(errors_fw), np.nanmean(errors_sw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_under_overestimate(fw_shock_values_pred, sw_shock_values_pred, fw_shock_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_reopenings = False\n",
    "\n",
    "last_day = 120 #may 5th. could be 120 for may first\n",
    "# second wave\n",
    "sw_shock_values = 100*(1-np.exp(-np.median(samples_shock['alpha_delta'], axis=0)))\n",
    "sw_shock_values_pred = 100*(1-np.exp(np.array([x for _, x, _, _, _, _ in shock_cms_info_comb]))).T\n",
    "sw_reopening_mask = np.array([x for _, _,_, x, _, _ in shock_cms_info_comb])\n",
    "\n",
    "if ignore_reopenings:\n",
    "    sw_shock_values[sw_reopening_mask] = np.nan\n",
    "\n",
    "for s_i in range(len(shock_cms_info_comb)):\n",
    "    if shock_cms_info_comb[s_i][4] >= last_day:\n",
    "        sw_shock_values[s_i] = np.nan\n",
    "    \n",
    "sw_mse_ps = np.power(sw_shock_values - np.median(sw_shock_values_pred, axis=0), 2)\n",
    "\n",
    "# first wave\n",
    "fw_shock_values = 100*(1-np.exp(-np.median(samples_shock['alpha_delta'], axis=0)))\n",
    "fw_shock_values_pred = 100*(1-np.exp(np.array([x for _, _, x, _, _, _ in shock_cms_info_comb]))).T\n",
    "fw_reopening_mask = np.array([x for _,_, _, x, _, _ in shock_cms_info_comb])\n",
    "\n",
    "if ignore_reopenings:\n",
    "    fw_shock_values[fw_reopening_mask] = np.nan\n",
    "    \n",
    "for s_i in range(len(shock_cms_info_comb)):\n",
    "    if shock_cms_info_comb[s_i][4] >= last_day:\n",
    "        fw_shock_values[s_i] = np.nan\n",
    "    \n",
    "fw_mse_ps = np.power(fw_shock_values - np.median(fw_shock_values_pred, axis=0), 2)\n",
    "\n",
    "shock_c = np.array([x[-1] for x in shock_cms_info_comb])\n",
    "country_relative_mses = np.zeros(len(countries))\n",
    "for c_i, c in enumerate(countries):\n",
    "    country_mask = shock_c == c_i\n",
    "    fw_mse_ps = np.power(fw_shock_values - np.median(fw_shock_values_pred, axis=0), 2)\n",
    "    fw_mse_ps[~country_mask] = np.nan\n",
    "    fw_mse_pc = np.nanmean(fw_mse_ps)\n",
    "    \n",
    "    sw_mse_ps = np.power(sw_shock_values - np.median(sw_shock_values_pred, axis=0), 2)\n",
    "    sw_mse_ps[~country_mask] = np.nan\n",
    "    sw_mse_pc = np.nanmean(sw_mse_ps)\n",
    "    \n",
    "    country_relative_mses[c_i] = sw_mse_pc / fw_mse_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3), dpi=500)\n",
    "plt.title('Relative Average Prediction Error')\n",
    "# plt.barh(countries, country_relative_mses, color='tab:gray')\n",
    "plt.scatter(country_relative_mses, countries, color='tab:gray', marker='d')\n",
    "plt.plot([1, 1], [-3, 8], 'k--', linewidth=0.5)\n",
    "plt.ylim((-0.5, 5.5))\n",
    "plt.xlim([0, 2])\n",
    "\n",
    "plt.xticks([0, 1, 2], [\"0%\", \"100%\", \"200%\"])\n",
    "plt.xlabel(\"\\nSecond wave MSE as a percentage of first wave MSE\")\n",
    "plt.text(0, -1.3, \"Second wave predicts better\", fontsize=6, ha='center')\n",
    "plt.text(1, -1.3, \"Waves predict equally well\", fontsize=6, ha='center')\n",
    "plt.text(2, -1.3, \"First wave predicts better\", fontsize=6, ha='center')\n",
    "plt.savefig('FigRelativePred.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
