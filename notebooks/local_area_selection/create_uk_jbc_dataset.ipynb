{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load UK NPI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_npi_df = pd.read_csv('../../data/raw_data_w_sources/uk_JBC_NPI_data.csv')\n",
    "uk_npi_df['date'] = pd.to_datetime(uk_npi_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/raw_data_w_sources/uk_ltla_info.json') as json_file:\n",
    "    uk_ltla_info_dict = json.load(json_file)\n",
    "\n",
    "uk_ltla_info_df = pd.DataFrame([d['attributes'] for d in uk_ltla_info_dict['features']])\n",
    "uk_ltla_info_df = uk_ltla_info_df.rename({'LAU117NM': 'area', 'NUTS318NM': 'NUTS3', 'NUTS118NM': 'region', 'NUTS218NM':'NUTS2'} ,axis=1)\n",
    "uk_ltla_info_df = uk_ltla_info_df.set_index('area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltla_to_nuts3_lookup(ltla):\n",
    "    if ltla in uk_ltla_info_df.index:\n",
    "        return uk_ltla_info_df.loc[ltla]['NUTS3']\n",
    "    else:\n",
    "        print(f'{ltla} missing from lookup')\n",
    "        return 'unknown NUTS3'\n",
    "    \n",
    "uk_npi_df['NUTS3'] = uk_npi_df['ltla'].map(ltla_to_nuts3_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load case and death data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_df = pd.read_csv('../../data/raw_data_w_sources/uk_case_deaths.csv', infer_datetime_format=True)\n",
    "uk_df = uk_df.drop(['areaCode', 'newCasesByPublishDate', 'newDeaths28DaysByPublishDate'], axis=1)\n",
    "uk_df['areaType'] = 'UK'\n",
    "uk_df = uk_df.rename({'areaType': 'country', 'areaName':'area', 'newCasesBySpecimenDate': 'new_cases', 'newDeaths28DaysByDeathDate': 'new_deaths'}, axis=1)\n",
    "uk_df['date'] = pd.to_datetime(uk_df['date'])\n",
    "uk_df = uk_df.set_index(['area', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_df = uk_df.sort_index(level=[1],ascending=[True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct set to model on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only have until late november in terms of UK NPI data.\n",
    "Ds = pd.date_range('2020-08-01', '2020-11-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['Durham CC',\n",
    " 'Warwickshire',\n",
    " 'West Surrey',\n",
    " 'East Merseyside',\n",
    " 'Greater Manchester North West',\n",
    " 'Berkshire',\n",
    " 'Gloucestershire',\n",
    " 'Worcestershire',\n",
    " 'Leeds',\n",
    " 'Barnsley, Doncaster and Rotherham',\n",
    " 'Leicestershire CC and Rutland',\n",
    " 'Hertfordshire',\n",
    " 'Merton, Kingston upon Thames and Sutton',\n",
    " 'Tyneside',\n",
    " 'Liverpool',\n",
    " 'Sheffield',\n",
    " 'Wirral',\n",
    " 'Sunderland',\n",
    " 'Sandwell',\n",
    " 'South and West Derbyshire',\n",
    " 'Cheshire West and Chester',\n",
    " 'Essex Haven Gateway',\n",
    " 'Barnet',\n",
    " 'Hounslow and Richmond upon Thames',\n",
    " 'Cambridgeshire CC',\n",
    " 'Cheshire East',\n",
    " 'Central Hampshire',\n",
    " 'Croydon',\n",
    " 'Oxfordshire',\n",
    " 'Manchester',\n",
    " 'Haringey and Islington',\n",
    " 'Calderdale and Kirklees',\n",
    " 'Ealing',\n",
    " 'Kent Thames Gateway',\n",
    " 'South Hampshire',\n",
    " 'Heart of Essex',\n",
    " 'East Riding of Yorkshire',\n",
    " 'Dudley',\n",
    " 'West Sussex (North East)',\n",
    " 'Lambeth',\n",
    " 'North Northamptonshire',\n",
    " 'West Essex',\n",
    " 'Enfield',\n",
    " 'Derby',\n",
    " 'Sefton',\n",
    " 'Buckinghamshire CC',\n",
    " 'Hackney and Newham',\n",
    " 'South Teesside',\n",
    " 'Nottingham',\n",
    " 'Bedford',\n",
    " 'Southend-on-Sea',\n",
    " 'East Derbyshire',\n",
    " 'Wiltshire',\n",
    " 'South Nottinghamshire',\n",
    " 'Mid Kent',\n",
    " 'West Sussex (South West)',\n",
    " 'Kingston upon Hull, City of',\n",
    " 'West Kent',\n",
    " 'Northumberland',\n",
    " 'Medway',\n",
    " 'Kensington & Chelsea and Hammersmith & Fulham',\n",
    " 'Lancaster and Wyre',\n",
    " 'East Lancashire',\n",
    " 'Coventry',\n",
    " 'Milton Keynes',\n",
    " 'North and North East Lincolnshire',\n",
    " 'Stoke-on-Trent',\n",
    " 'Plymouth',\n",
    " 'Isle of Wight',\n",
    " 'Peterborough',\n",
    " 'Camden and City of London',\n",
    " 'Southampton',\n",
    " 'Swindon',\n",
    " 'Brighton and Hove',\n",
    " 'Telford and Wrekin',\n",
    " 'Bristol, City of',\n",
    " 'Torbay',\n",
    " 'Portsmouth',\n",
    " 'York',\n",
    " 'Breckland and South Norfolk']\n",
    "\n",
    "uk_df_list = []\n",
    "npis = uk_npi_df.columns[6:-115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_active_cms = np.zeros((len(regions), len(npis), len(Ds)))\n",
    "new_cases = np.zeros((len(regions), len(Ds)))\n",
    "new_deaths = np.zeros((len(regions), len(Ds)))\n",
    "\n",
    "for region_i, region in enumerate(regions):\n",
    "    filtered_df = uk_npi_df.loc[uk_npi_df['NUTS3'] == region]\n",
    "    \n",
    "    # npi data first\n",
    "    ltlas = filtered_df['ltla'].unique()\n",
    "    n_ltlas = len(ltlas)\n",
    "    \n",
    "    active_cms = np.zeros((len(ltlas), len(npis), len(Ds)))\n",
    "    filtered_df = filtered_df.set_index(['ltla', 'date'])\n",
    "    \n",
    "    for ltla_index, ltla in enumerate(ltlas):\n",
    "        ltla_df = filtered_df.loc[ltla].loc[Ds]\n",
    "        for npi_index, npi in enumerate(npis):\n",
    "            active_cms[ltla_index, npi_index, :] = ltla_df[npi]\n",
    "        \n",
    "        if ltla in uk_df.index.unique(0):\n",
    "            new_cases[region_i, :] += uk_df.loc[ltla]['new_cases'].loc[Ds].to_numpy()\n",
    "            new_deaths[region_i, :] += uk_df.loc[ltla]['new_deaths'].loc[Ds].to_numpy()\n",
    "        \n",
    "    all_active_cms[region_i, :, :] = np.all(active_cms, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'new_cases': new_cases, \n",
    "    'new_deaths': new_deaths,\n",
    "    'active_cms': all_active_cms,\n",
    "    'regions': regions,\n",
    "    'days': Ds,\n",
    "    'CMs': list(npis),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(data_dict, open('uk_test_set.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
