{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What was the effective region size in the UK?\n",
    "\n",
    "We want to decide between running things at a LTLA level (LAU1), or a NUTS 3 level. To do this, we will use the JBC LTLA data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load UK NPI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_npi_df = pd.read_csv('../../data/raw_data_w_sources/UK_JBC_NPI_data.csv')\n",
    "uk_npi_df['date'] = pd.to_datetime(uk_npi_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/raw_data_w_sources/uk_ltla_info.json') as json_file:\n",
    "    uk_ltla_info_dict = json.load(json_file)\n",
    "\n",
    "uk_ltla_info_df = pd.DataFrame([d['attributes'] for d in uk_ltla_info_dict['features']])\n",
    "uk_ltla_info_df = uk_ltla_info_df.rename({'LAU117NM': 'area', 'NUTS318NM': 'NUTS3', 'NUTS118NM': 'region', 'NUTS219NM':'NUTS2'} ,axis=1)\n",
    "uk_ltla_info_df = uk_ltla_info_df.set_index('area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltla_to_nuts3_lookup(ltla):\n",
    "    if ltla in uk_ltla_info_df.index:\n",
    "        return uk_ltla_info_df.loc[ltla]['NUTS3']\n",
    "    else:\n",
    "        print(f'{ltla} missing from lookup')\n",
    "        return 'unknown NUTS3'\n",
    "    \n",
    "uk_npi_df['NUTS3'] = uk_npi_df['ltla'].map(ltla_to_nuts3_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS3_regions = uk_npi_df['NUTS3'].unique()\n",
    "ltlas = uk_npi_df['ltla'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you want to make a csv with this information in!\n",
    "#uk_npi_df.to_csv('england_jbc_npi_w_nuts3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: some ltlas missing\n",
    "\n",
    "There are ~400 in the UK (380 regions by cases and deaths data on the dashboard), so it seems that some areas are missing here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(ltlas)} LTLAs represented here')\n",
    "print(f'There are {len(NUTS3_regions)} NUTS3 area represented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many LTLAs are in each NUTS3 region?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltlas_per_nuts3 = np.zeros(len(NUTS3_regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, nuts3_region in enumerate(NUTS3_regions):\n",
    "    if 'unknown' in nuts3_region:\n",
    "        continue\n",
    "    \n",
    "    filtered_uk_npi_df = uk_npi_df.loc[uk_npi_df['NUTS3'] == nuts3_region]\n",
    "    \n",
    "    ltlas = filtered_uk_npi_df['ltla'].unique()\n",
    "    n_ltlas = len(ltlas)\n",
    "    \n",
    "    ltlas_per_nuts3[i] = n_ltlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(ltlas_per_nuts3)\n",
    "plt.title('LTLAs per NUTS3 Region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The NUTS3 with the most LTLAs is {NUTS3_regions[np.argmax(ltlas_per_nuts3)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is confirmed here: https://www.ons.gov.uk/methodology/geography/ukgeographies/eurostat#london"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are NUTS3 {np.sum(ltlas_per_nuts3 > 1)} with more than 1 LTLAs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the represented NUTS3 regions, this is half. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NPI data per NUTS3 region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds = pd.date_range(start='2020-08-01', end='2020-12-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts3_npi_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npis = uk_npi_df.columns[6:-114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The NPIs we are considering are {npis}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, nuts3_region in enumerate(NUTS3_regions):\n",
    "    if 'unknown' in nuts3_region:\n",
    "        continue\n",
    "    \n",
    "    filtered_uk_npi_df = uk_npi_df.loc[uk_npi_df['NUTS3'] == nuts3_region]\n",
    "    \n",
    "    ltlas = filtered_uk_npi_df['ltla'].unique()\n",
    "    n_ltlas = len(ltlas)\n",
    "    \n",
    "    active_cms = np.zeros((len(ltlas), len(npis), len(Ds)))\n",
    "    filtered_uk_npi_df = filtered_uk_npi_df.set_index(['ltla', 'date'])\n",
    "    \n",
    "    if n_ltlas > 2:\n",
    "        for ltla_index, ltla in enumerate(ltlas):\n",
    "            ltla_df = filtered_uk_npi_df.loc[ltla].loc[Ds]\n",
    "            for npi_index, npi in enumerate(npis):\n",
    "                active_cms[ltla_index, npi_index, :] = ltla_df[npi]\n",
    "                \n",
    "    nuts3_npi_dict[nuts3_region] = active_cms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute discrepancies per NPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts3_npi_consistency_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nuts3_region in NUTS3_regions:\n",
    "    if 'unknown' in nuts3_region:\n",
    "        continue\n",
    "        \n",
    "    active_cms = nuts3_npi_dict[nuts3_region]\n",
    "    nLTLAs, nCMs, nDs = active_cms.shape\n",
    "    \n",
    "    cms_consistent = np.zeros((nCMs, nDs))\n",
    "    \n",
    "    for npi_i in range(nCMs):\n",
    "        cms_consistent[npi_i, :] = np.all(active_cms[:, npi_i, :] == active_cms[0, npi_i, :], axis=0)\n",
    "        \n",
    "    nuts3_npi_consistency_dict[nuts3_region] = cms_consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute discrepancy per NPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nuts3_days = (len(NUTS3_regions) - 1) * nDs\n",
    "npi_consistent_days = np.zeros(len(npis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nuts3_region, npi_consistency_mat in nuts3_npi_consistency_dict.items():\n",
    "    npi_consistent_days += np.sum(npi_consistency_mat, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_days_inconsistent = total_nuts3_days - npi_consistent_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 3), dpi=300)\n",
    "sns.barplot(npis, total_days_inconsistent)\n",
    "plt.title(f'Total Num days NPIs in NUTS3 region were inhomogenous\\n(out of {total_nuts3_days} datapoints)\\nAug1-Dec12')\n",
    "plt.xticks(rotation=-90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npis_with_inconsistencies = np.nonzero(total_days_inconsistent)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more questions:\n",
    "\n",
    "- How many NUTS3 areas have these inconsistencies?\n",
    "- What do the inconsistencies look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts3_regions_with_inconsistencies = []\n",
    "\n",
    "for nuts3_region, npi_consistency_mat in nuts3_npi_consistency_dict.items():\n",
    "    inconsistencies = np.sum(npi_consistency_mat == 0)\n",
    "    if inconsistencies > 0:\n",
    "        nuts3_regions_with_inconsistencies.append(nuts3_region)\n",
    "        print(f'{nuts3_region} has {inconsistencies} inconsistencies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(nuts3_regions_with_inconsistencies)} out of {len(NUTS3_regions)} NUTS3 regions have some inconsistency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inconsistent_nuts3 in nuts3_regions_with_inconsistencies:\n",
    "    plt.figure(figsize=(10, 8), dpi=300)\n",
    "    cms = nuts3_npi_dict[inconsistent_nuts3] \n",
    "    n_ltlas, _, nDs = cms.shape\n",
    "    \n",
    "    for plot_i, npi_i in enumerate(npis_with_inconsistencies):\n",
    "        plt.subplot(6, 2, plot_i+1)\n",
    "        plt.title(npis[npi_i])\n",
    "        for ltla in range(n_ltlas):\n",
    "            plt.plot(np.arange(nDs), cms[ltla, npi_i, :]+0.05*np.random.normal(size=1))\n",
    "        plt.xlabel('days after 1st aug')\n",
    "        plt.yticks([0, 1], ['NPI Inactive', 'NPI_Active'])\n",
    "    plt.suptitle(inconsistent_nuts3)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUTS3 looks mostly fine in the UK. There are small number of discrepencies in some regions (<10% of them), and these discrepancies only affect the above NPIs. \n",
    "\n",
    "Sampling will mean we only pick up a small number of these regions, and in most regions, the discrepancies look ok (i.e., delays rather than completely different policies). There are some NUTS3 regions where the discrepancies look a bit problematic - namely leicester, lancashire, and some of manchester. \n",
    "\n",
    "An open question remains on getting case and death data at this level - as some local areas seem to be in multiple nuts 3 regions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
